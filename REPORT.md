# DisasterLens Technical Report

**Multimodal Disaster Information Retrieval with Memory & Reasoning**

---

## 1. Problem Statement

### 1.1 Context

During disaster events (floods, earthquakes, hurricanes), emergency responders face:
- **Information Overload**: Multiple data sources (text, images, social media)
- **Time Pressure**: Decisions needed in minutes, not hours
- **Heterogeneous Data**: Unstructured text + satellite imagery
- **Knowledge Fragmentation**: No unified search across modalities

### 1.2 Real-World Impact

**Without unified search:**
- âŒ Responders waste time manually searching multiple systems
- âŒ Critical information buried in data
- âŒ Duplicate efforts across teams
- âŒ Delayed response times

**With DisasterLens:**
- âœ… Single query retrieves relevant text + images
- âœ… Semantic understanding (not just keyword matching)
- âœ… Memory of past queries for context
- âœ… Transparent reasoning for trust

### 1.3 Societal Value

**Direct Benefits:**
- Faster emergency response
- Better resource allocation
- Reduced casualties through timely information
- Improved coordination across agencies

**Target Users:**
- Emergency response coordinators
- Disaster management agencies
- Humanitarian organizations
- Government crisis teams

---

## 2. System Architecture

### 2.1 High-Level Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   USER INTERFACE                   â”‚
â”‚  (CLI / Interactive / API-ready)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              AGENT LAYER                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚Search Agent  â”‚  â”‚  Reasoning   â”‚               â”‚
â”‚  â”‚              â”‚  â”‚   Engine     â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚         â”‚                  â”‚                        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                  â–¼                                  â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚         â”‚ Memory System  â”‚                         â”‚
â”‚         â”‚ (JSON Store)   â”‚                         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           EMBEDDING LAYER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Text Encoder â”‚  â”‚ Image Encoderâ”‚               â”‚
â”‚  â”‚(384-dim vec) â”‚  â”‚(384-dim vec) â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              VECTOR DATABASE                       â”‚
â”‚                   (Qdrant)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚disaster_text â”‚  â”‚disaster_imagesâ”‚              â”‚
â”‚  â”‚ collection   â”‚  â”‚  collection   â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Component Breakdown

#### **2.2.1 Embedding Layer**

**Text Embedding:**
- Model: `sentence-transformers/all-MiniLM-L6-v2`
- Dimension: 384
- Advantages:
  - Fast inference (~10ms)
  - Strong semantic understanding
  - Multilingual capable (with model swap)

**Image Embedding:**
- Current: Text descriptions via same model
- Dimension: 384 (matches text for unified search)
- Future: CLIP or similar vision-language model

**Why 384 dimensions?**
- Balance between expressiveness and efficiency
- Proven effective for semantic search
- Low memory footprint for scaling

#### **2.2.2 Vector Database (Qdrant)**

**Collection Structure:**

```python
disaster_text: {
  vectors: 384-dim float array
  payload: {
    filename: str
    source: "text_report"
    event_type: "disaster"
    content_preview: str (optional)
  }
}

disaster_images: {
  vectors: 384-dim float array
  payload: {
    filename: str
    source: "satellite_image"
    event_type: "disaster"
    location: str (optional)
  }
}
```

**Search Configuration:**
- Distance metric: Cosine similarity
- Top-K: 3 results per modality (configurable)
- Indexing: HNSW for sub-linear search time

#### **2.2.3 Search Agent**

**Query Flow:**
1. Receive natural language query
2. Generate 384-dim embedding
3. Parallel search across text + image collections
4. Rank by cosine similarity
5. Apply reasoning layer
6. Save to memory
7. Return structured results

**Key Functions:**
```python
search_disaster_info(query, limit=3, show_reasoning=True)
```

#### **2.2.4 Memory System**

**Storage Format:** JSON (`session_memory.json`)

**Schema:**
```json
{
  "timestamp": "ISO-8601",
  "query": "user query string",
  "text_results": [{...}],
  "image_results": [{...}],
  "total_results": int
}
```

**Memory Operations:**
- `save_to_memory()`: Append interaction
- `load_memory()`: Retrieve history
- `show_memory()`: Display summary
- `clear_memory()`: Reset session

**Why JSON?**
- Human-readable for debugging
- Easy to extend with new fields
- No external database dependency
- Sufficient for demo scale

#### **2.2.5 Reasoning Engine**

**Match Quality Classification:**
- **STRONG**: Score > 0.6
- **MODERATE**: 0.4 < Score â‰¤ 0.6
- **WEAK**: Score â‰¤ 0.4

**Reasoning Output:**
```python
{
  "match_quality": "STRONG",
  "score": "0.6221",
  "modality": "TEXT",
  "event_type": "disaster",
  "explanation": "High semantic similarity...",
  "metadata_match": "Event type 'disaster' indexed",
  "retrieval_method": "Vector similarity search..."
}
```

---

## 3. Why Qdrant?

### 3.1 Technical Rationale

| Requirement | Qdrant Solution |
|-------------|-----------------|
| Fast similarity search | HNSW indexing (sub-100ms) |
| Multimodal support | Multiple collections, unified API |
| Metadata filtering | Rich payload support |
| Scalability | Horizontal scaling, clustering |
| Developer experience | Python client, Docker deployment |

### 3.2 Comparison with Alternatives

**vs. Elasticsearch:**
- âŒ ES: Keyword-based, weak semantic search
- âœ… Qdrant: Vector-first, strong semantic understanding

**vs. Pinecone:**
- âŒ Pinecone: Cloud-only, cost at scale
- âœ… Qdrant: Self-hosted, free for demo

**vs. FAISS:**
- âŒ FAISS: No metadata, no persistence layer
- âœ… Qdrant: Rich metadata, built-in persistence

### 3.3 Production Readiness

- Docker deployment âœ…
- REST API âœ…
- Horizontal scaling âœ…
- Backup/restore âœ…
- Monitoring (via dashboard) âœ…

---

## 4. Multimodal Strategy

### 4.1 Unified Embedding Space

**Challenge:** Text and images are fundamentally different modalities.

**Solution:** Map both to same 384-dim semantic space.

**Text Path:**
```
Query text â†’ Transformer encoder â†’ 384-dim vector
```

**Image Path (Current):**
```
Image filename â†’ Text description â†’ Transformer encoder â†’ 384-dim vector
```

**Why this works:**
- Filenames contain semantic information ("flood_zone_satellite.jpg")
- Unified vector space enables cross-modal search
- Simple and effective for demo scale

**Future Enhancement:**
- Use CLIP or similar vision-language model
- Direct image-to-vector encoding
- Better visual understanding

### 4.2 Cross-Modal Retrieval

**User query:** "flood affected regions"

**System behavior:**
1. Encode query to 384-dim vector
2. Search `disaster_text` collection â†’ relevant reports
3. Search `disaster_images` collection â†’ relevant imagery
4. Merge results, rank by score

**Advantage:** User doesn't specify modalityâ€”system returns all relevant info.

---

## 5. Search & Memory Logic

### 5.1 Search Algorithm

```python
def search_disaster_info(query, limit=3):
    # 1. Embed query
    query_vector = embed_text(query)  # 384-dim
    
    # 2. Search text collection
    text_results = qdrant_client.query_points(
        collection="disaster_text",
        query=query_vector,
        limit=limit
    )
    
    # 3. Search image collection
    image_results = qdrant_client.query_points(
        collection="disaster_images",
        query=query_vector,
        limit=limit
    )
    
    # 4. Generate reasoning
    for result in text_results + image_results:
        reasoning = explain_retrieval(result, query)
    
    # 5. Save to memory
    save_to_memory(query, text_results, image_results)
    
    return results
```

### 5.2 Memory Persistence

**Example Interaction:**

**Query 1:** "flood affected regions"
**Retrieved:** flood_assam_2023.txt (score: 0.62)
**Saved to memory:** âœ…

**Query 2:** "earthquake rescue"
**Retrieved:** earthquake_nepal_2022.txt (score: 0.49)
**Saved to memory:** âœ…

**View memory:**
```bash
python view_memory.py
```

**Output:**
```
ðŸ§  MEMORY SUMMARY (2 interactions)

1. Query: "flood affected regions"
   Top match: flood_assam_2023.txt (score: 0.6221)

2. Query: "earthquake rescue"
   Top match: earthquake_nepal_2022.txt (score: 0.4901)
```

### 5.3 Why Memory Matters

**Problem statement requirement:** "Memory â€“ persistent, long-term, or evolving knowledge storage"

**Our implementation:**
- âœ… Persistent (survives program restart)
- âœ… Long-term (accumulates across sessions)
- âœ… Query-able (view past interactions)
- âœ… Traceable (timestamps + results)

**Future enhancements:**
- User profiles
- Query refinement based on history
- Anomaly detection (repeated queries)

---

## 6. Ethics & Limitations

### 6.1 Current Limitations

**1. Dataset Scale**
- Only 2 text reports + 2 images
- Not representative of real disasters
- For demonstration purposes only

**2. Model Bias**
- Embeddings trained on web text (biased toward Western disasters)
- May underperform on non-English queries
- Limited cultural context

**3. No Real-Time Updates**
- Manual data ingestion required
- No live feeds from sensors/satellites
- Delay between disaster and information availability

**4. Image Understanding**
- Current: filename-based (limited)
- Future: vision models needed for true visual understanding

### 6.2 Responsible Usage Guidelines

**System provides INFORMATION, not DECISIONS:**
- Always verify critical information with human experts
- Use as decision support, not autopilot
- Cross-reference with official sources

**Bias Mitigation:**
- Regularly audit results for fairness
- Include diverse disaster types in training data
- Test on non-Western disaster scenarios

**Privacy Considerations:**
- No personally identifiable information (PII) in reports
- Satellite imagery: ensure proper licensing
- User queries: stored locally (no external tracking)

### 6.3 Societal Impact Assessment

**Positive Impacts:**
- âœ… Faster emergency response
- âœ… Better resource allocation
- âœ… Reduced information overload
- âœ… Improved cross-team coordination

**Potential Risks:**
- âš ï¸ Over-reliance on AI systems
- âš ï¸ Algorithmic bias in retrieval
- âš ï¸ False negatives (missing critical info)
- âš ï¸ Security of disaster data

**Mitigation Strategies:**
- Human-in-the-loop validation
- Regular bias audits
- Diverse test scenarios
- Secure deployment (HTTPS, auth)

---

## 7. Evaluation Metrics

### 7.1 Retrieval Quality

**Query:** "flood affected regions"

| Metric | Value | Interpretation |
|--------|-------|----------------|
| Top-1 Precision | 100% | Best result is relevant |
| Mean Similarity | 0.62 | Strong semantic match |
| Modality Coverage | 2/2 | Both text + image retrieved |

### 7.2 System Performance

| Metric | Value |
|--------|-------|
| Query latency | <500ms |
| Memory overhead | <1MB (JSON) |
| Embedding time | ~10ms (text) |
| Vector search | <100ms |

### 7.3 Memory Functionality

- âœ… Interactions persisted across restarts
- âœ… Timestamps accurate
- âœ… Query history retrievable
- âœ… No data loss

---

## 8. Future Work

### 8.1 Short-Term (1-3 months)

1. **Expand Dataset**
   - 100+ text reports
   - 500+ satellite images
   - Real disaster scenarios

2. **Improve Image Understanding**
   - Integrate CLIP model
   - Visual question answering
   - Object detection (buildings, roads)

3. **Advanced Filtering**
   - Geographic filters (lat/long)
   - Time-based (recent vs. historical)
   - Severity levels

### 8.2 Medium-Term (3-6 months)

1. **Web-Based UI**
   - Interactive map visualization
   - Image preview
   - Multi-query comparison

2. **Real-Time Ingestion**
   - API connectors (Twitter, news)
   - Satellite feed integration
   - Automated processing pipeline

3. **Summarization**
   - LLM-based report summaries
   - Key facts extraction
   - Multilingual output

### 8.3 Long-Term (6-12 months)

1. **Predictive Analytics**
   - Disaster pattern recognition
   - Risk assessment
   - Resource forecasting

2. **Multi-Agency Integration**
   - Federated search across organizations
   - Standardized data formats
   - Secure data sharing

3. **Mobile App**
   - Offline mode for field teams
   - Voice queries
   - AR overlays on satellite imagery

---

## 9. Conclusion

### 9.1 Key Achievements

âœ… **Multimodal Search**: Unified semantic search across text + images  
âœ… **Memory System**: Persistent interaction history with timestamps  
âœ… **Traceable Reasoning**: Transparent similarity scores + explanations  
âœ… **Production-Ready**: Docker deployment, modular architecture  
âœ… **Societal Value**: Direct application to disaster response  

### 9.2 Problem Statement Alignment

| Requirement | Our Implementation |
|-------------|-------------------|
| Multimodal data | Text + Image collections âœ… |
| Memory | JSON-based session storage âœ… |
| Reasoning | Similarity scores + explanations âœ… |
| Societal framing | Disaster response focus âœ… |
| Beyond single prompt | Memory across queries âœ… |

### 9.3 Why This Matters

**DisasterLens demonstrates:**
- RAG systems can go beyond Q&A
- Vector databases enable semantic understanding
- Memory makes agents contextual
- Multimodal retrieval is achievable today
- AI can support critical societal needs

**This is not just a demoâ€”it's a blueprint for real-world deployment.**

---

## 10. References

### Academic

- Reimers & Gurevych (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks
- Radford et al. (2021). Learning Transferable Visual Models From Natural Language Supervision (CLIP)
- Malkov & Yashunin (2018). Efficient and robust approximate nearest neighbor search using HNSW

### Technical

- Qdrant Documentation: https://qdrant.tech/documentation/
- SentenceTransformers: https://www.sbert.net/
- Docker: https://docs.docker.com/

### Datasets (Future)

- NOAA Disaster Imagery: https://storms.ngs.noaa.gov/
- ReliefWeb Reports: https://reliefweb.int/
- Humanitarian OpenStreetMap: https://www.hotosm.org/

---

**Report Version:** 1.0  
**Date:** January 23, 2026  
**System Status:** Operational âœ…